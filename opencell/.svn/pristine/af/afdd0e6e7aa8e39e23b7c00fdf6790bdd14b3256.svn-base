\section{Evaluation}

\subsection{Emulation}
We first briefly explain the experiments' setups and then show the results. 
\subsubsection{Setup}
We build our own emulation testbed to evaluate the performance gain from in-network knowledge. We have a server which gets video play bit rate requests, and sends video chunks with the requested play bit rate to the clients. We take 10 different video encoding rates from Netflix: $\{0.235, \dots$ $, 4.3\} $ Mbps. Since the requested rates are average bit rates and the chunk bit rates may vary based on whether the scene is static, we add randomization factor (0.2-2) for the video chunks and a weak correlation between two conservative chunks ($rate_{i+1} = rate_{i}*0.4 + 0.6* randomization\;factor$), the similar approximations are also used in previous works.\emph{BBA citation} The clients are running various video streaming algorithms such as BBA2, FESTIVE and QDASH. The server and the clients are both connected to a dummynet\cite{Dummynet}, which acts like an eNobeB and enforces scheduling or rate limiting. To expose the in-network knowledge, we build a different channel between dummynet (eNodeB) and the client. In fact an alternative approach is to convey the knowledge to the server and let the server decide.   
\begin{figure}[hb]
 \includegraphics[width=\linewidth]{architecture.jpg}
 \centering
 \caption{Illustration of Video Buffer}
\end{figure}

\emph{Trace Selection}: we choose to use both LTE and 3G traces from both MIT experiments \cite{Sprout} and AT\&T lab. For MIT traces, it has all major carriers and for business reason, we anonymize all traces and name them as LTE-a, LTE-b, LTE-c and 3G-a. \emph{Essentially they are Verizon LTE, MIT ATT4g, and ATT lab 4g, and sprint 3g}. 

\subsubsection{Results}


\subsection{Simulation}
\textit{Setup:} We take 10 different video encoding rates from Netflix: $\{0.235,\dots, 4.3\}$ Mbps, and we run the offline algorithm from a simulation trace with 105 users using real trace radio information. We use IBM ILOG CPLEX Optimizer to solve the mixed integer programming in ubuntu 14.04 with linux kernel 3.13.0-27-generic. The offline algorithm allows cross boundry downloading, i.e., we can download one chunk in two time segments as far as we have residual bandwidth, and 
we do not consider overhead in encoding rate and retransmission; in practice, video with 1 Mbps encoding rate usually consumes more than 1 Mbps bandwidth. The results from this offline algorithm can be used as a theoretical maximum for comparison, and help us understand the dynamics between the parameters in the system. Note the offline optimization prioritizes later chunks due to the waterfilling mechanism: it always uses residual bandwidth to download future chunks, so the future chunks can utilize both current and future bandwidth and thus have higher quality. 

\textit{Results:} 

Stability factor $\alpha$: we test different $\alpha$ values to see how the factor affects the dynamics between stability and efficiency. Through experiments we find $\alpha$ should be in a [1:5] range, any $\alpha>5$ leads to the condition where the video is stuck with low quality. 

$INTV$ for each segment: we test three different time segments \{2,5,10\} seconds, and find that the longer interval leads to better stability under the same $\alpha$ but the difference is trivial somehow. 

The number of prefetched chunks: we also find that for UEs with a reasonably stable maximum bandwidth (102/105 UEs), it requires at most prefetching chunks with a total playtime 20 seconds throughout the whole play, this ``magic" value is coincidentally used in Festive.   

Comparison between Festive and our offline approach: we use two parameters a=12 (stability index) and $p=0.85*HarmonicMean$ (0.85 is the bandwidth estimation discount factor), the two values taken from Festive. Since in Festive it assumes time interval is 2 seconds, so we also use 2 seconds interval per chunk in our evaluation. Festive can achieve an utilization of 64.3\%, and even if we take aggressive approach with no estimation bandwidth discount, i.e., $p=HarmonicMean$ still we can only get 68.7\% utilization. The reason is that Festive uses the historical harmonic mean as bandwidth estimation, which by nature underestimates the available bandwidth. In Festive for stability, the number of switches for quality is 0 with 0.85 discount factor, but constantly stuck with low quality; or 2 with no bandwidth discount. On the contrary even if we take a fair factor in stability, in this case, $\alpha=5$, our approach can still get 89.5\% utilization, while there is only one jump in the video quality.   

Based on the above observations and the reality, we decide to set $\alpha=5$ and $INTV=10s$ (for netflix, the time interval for each segment is 2 seconds for streaming through wireline and 10 seconds through wireless). and $z= \frac{20}{INTV} = 2$.



 \begin{figure} [hb]
 \includegraphics[width=\linewidth]{Festive.png}
 \centering
 \caption{Comparison between Festive and our offline approach for UE13}
\end{figure}