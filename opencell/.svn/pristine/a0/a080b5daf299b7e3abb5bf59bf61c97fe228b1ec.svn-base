
\section{Architecture} \label{sec:Architecture}
This section starts with the architecture of a scalable prediction system in \autoref{subsec:prediction_system}, and then we discuss the feasibility and advantages of inline method to expose APIs in \autoref{subsec:exposingAPI}.
\subsection{Scalable Prediction System} \label{subsec:prediction_system}
We propose a two-tiered system to implement an API computing system. We have a proxy sitting at dataplane; and local and central bandwidth estimator at control plane. The local bandwidth estimator communicates with eNodeBs and it takes channel quality, number of active users, cell load and users' queue size etc. information as inputs and compute the available bandwidth for each user. A local bandwidth estimator is logically distributed in the RAN and thus can be easily scale-out. Meanwhile the central bandwidth estimator sits in the core network and it summarizes local BW estimation and MME Mobility information to compute the final bandwidth prediction for a user. In most cases one local estimation is enough, however in cases like handoff we need choose among several local estimations. In terms of scalability for central estimator, it should be also scale-out with MMEs. Our architecture is generic and able to integrate into both 3G and 4G networks. 

Once the computation work is finished, the central estimator sends the information to the proxy. 
 
\begin{figure}[b]\label{fig:Architecture}
 \includegraphics[width=\linewidth]{architecture2.pdf}
 \caption{Architecture for API Computing And Feedback}
\end{figure}


\subsection{API Exposure}\label{subsec:exposingAPI}
Current cellular network practice already uses proxy in the core network for pacing purpose. It splits the TCP connection into two: server$\leftrightarrow $proxy and proxy$\leftrightarrow $client. We can utilize the proxy for API exposure. \emph{Sending to the server or the client?} We argue that exposing the APIs to the server causes less security concerns. It also reduces the traffic in the core network as sending to the client requires central estimator to send back to local ones again. However since we let the server decide and the server may selectively choose some network statistics and send to the client. 

In terms of encoding the APIs, there are several options: (i) in TCP; (ii) in HTTP; and (iii) through a new connection. Inline methods have advantages over new connection. First new connection method doubles the connections between the server and the proxy. Second in practice CDNs are using public IPs, and the intial and new connections may be directed to different private servers in CDN load balancer. Between inline methods TCP is more practical since many streaming services are using secure HTTP which requires encrytion/decryption to modify the header. Since most of the video traffic is from the server to the client, and only some playback acknowledgement packets are sent from the client to the server, extending the option fields in TCP from the proxy to the server only adds moderate amount of overhead in TCP.
