

\section{Measurement study and Key metrics prediction}\label{sec:prediction}
In \autoref{subsec:ltenet} we show in proportional fair scheduler the available bandwidth for each user is a function of (i) number of users in each cell, and (ii) the channel quality for each user, so the predictability of the two determines the estimated bandwidth. In this section we conduct an extensive measurement study to show the predictability of the link channel quality and the load on eNodeBs in \autoref{subsec:CQ} and \autoref{subsec:NUser} respectively. 

The traces are collected between Jun and July 2014 over several geolocations in the United States from a major cellular carrier, it covers more than half million users and over 2000 eNodeBs. The traces have been anonymized before handing to us for privacy reasons. 

\subsection{Proportional Fair Scheduler}\label{subsec:ltenet}
3G ad 4G networks are using Orthogonal Frequency-Division Multiuser Access(OFDMA) scheme to achieve high spectrum efficiency. To achieve multiuser diversity, NodeBs and eNodeBs are running variations of proportional fair scheduling system. A basic \textit{proportional fair scheduler} works as the following: eNodeBs obtain the feedback from each user about their instantaneous channel quality conditions (CQ) in terms of encoding rate per resource block, and take the ratio between it and historial mean of CQ and pick the user with the maximum ratio. In a static model over a long term, each user will get 1/N share of resource blocks if N is the static number of users in the cell, a dynamic model also has a similar result\cite{PFINFOCOM}. The maximum bandwidth for each user in a cell is a function of: $T$-number of resource blocks in the cell, $N$-number of users in the cell, and $\mathbf{CQ}$-channel quality vector for all users; so maximum bandwidth vector for all users $\mathbf{BW} = f(T, N, \mathbf{CQ})$. We do not directly address $f(T, N, \mathbf{CQ})$ function in this paper as it is vendor-specific and mostly it is close to the basic PF scheduler. In the rest of the paper we assume a simple PF scheduler, that is $\mathbf{BW} = f(T, N, \mathbf{CQ})=\frac{T}{N}*\mathbf{CQ}$. Among the three variables, $T$ is predetermined by the hardware, $N$ and $\mathbf{CQ}$ are the two factors we need to predict. 

\subsection{the Channel Quality}\label{subsec:CQ}
One unique characteristic for cellular network is the high mobility. The link quality can fluctuate to a certain extent due to mobility and fading effects. There are several individual studies of link mobility\cite{InfoCom14, Sprout}, however the measurements are from individual devices. On the contrary our data set coveers a broad range of users and thus can give a better insight about channel quality. 

\emph{RSRQ:} Reference Signal Received Quality, is the key metric for the LTE wireless link. RSRQ senses the load from other users in the same cell and the neighboring cells, and is indexed in 0-34 integer numbers; a higher number indicates a better link quality. RSRQ values can be mapped to certain encoding rate.

\emph{Data summary:} The following plot is a 3 minutes snapshot at 12:00 pm GMT, Jun 11th, 2014.  Among all the users, we find most of the users have fairly stable link quality, 54.6\% of the users have a CV (coefficiency of variation) in terms of RSRQ within 0.2 and 84.1\% of the uses within 0.5, and 3.6\% of the users have very dynamic link with a CV higher than 1. We further found 96.2\% are active in less than 10\% of the time(18s), and their CV is significantly higher than the persistent users(>150s): 0.289 versus 0.153. The high CV for inactive users may be due to the sample points of two RSRQ reports being farther apart on time horizon such that the environmental factors have changed to a greater extent. 

\emph{The Occurence of Handoff}: in the dataset, handoff occurs for 30.7\% of the users, and average handoff occurence is 2.2 times. Through further investigation, we found repetitive switch between two or three neighboring cells is quite often in our dataset, mostly due to similar RSRQs ($\Delta RSRQ<5$) from both cells. 


\begin{figure}[ht]
\begin{minipage}[b]{1\linewidth}
\centering
\includegraphics[width=\linewidth]{distr.png}
\end{minipage}
\caption{Mean and Coefficiency of Variation of RSRQ for each user, a point represents a user}
\end{figure}

\subsection{the Cell Load}\label{subsec:NUser}
We monitored the LTE load on several locations in both east and west coasts: west coast is in north California and Los Angeles areas; and east coast includes New England and Goergia. The trace is taken from one continuous day monitor on Jun 8th, 2014. To find the correlation  between time and load, we separate the data based on eNodeB IDs which are categorized by their geolocation information. 
\emph{Utilization of a eNodeB}: each eNodeB counts the percentage of used resource blocks in an OFDMA scheduler and uses that as an indication of eNodeB load, the eNodeB polls the cell utilization at subsecond level. Through study we notice the high dynamicity of cell loads, in terms of both short and long term. Short term variation is close to stochastic model. Over 80\% of the cells in both east and west coast have an average load under 50\% during peak hours, while more than 50\% have reached 80\% utilization at some point during the peak hour. Not surprisingly, the cells with higher utilization have lower utilization variations.  In addition, we find a very noticeable ``seasonal" effect on cell load. The eNodeBs have substantially higher load during peak hours. 

\begin{figure}[t]
\centering
 \includegraphics[width=\linewidth]{peakload.png}
\caption{Percentage of Cells falls into heavy load, time is using GMT }
\end{figure}

\begin{table*}
\begin{tabular} {|c |c |}
\hline
Notation&Meaning\\ \hline
$T$ &the number of time segments\\ \hline
$M$ &the number of video quality levels (encoding bit rates)\\ \hline
$R_i$& the rate for the video with $i^{th}$ highest encoding bit rate\\ \hline
$x_i^t$&indicator of encoding of $R_i$ video play rate at time t, used in offline algorithm \\ \hline
$E$& utilization of used bandwidth over maximum available bandwidth \\ \hline
$\phi^t$ &the number of quality jumps between two consecutive chunks at time t\\ \hline
$C $ &the estimated capacity\\ \hline
$B $ &the buffer occupancy(seconds of video) \\ \hline
$z $ &the maximum buffer size (seconds of video) \\ \hline
$t $ &the recommended buffer size (seconds of video) \\ \hline
\end{tabular}
\centering
\caption{Variables for Optimization}
\end{table*}




\begin{comment}

\section{Design} \label{sec:optimization}
In this section, we explain the reason to choose an \textbf{\emph{end-to-end decision making with in-network knowledge}} model in section \ref{designchoice}, we then explain the our architecture in section \ref{architecture}. 
%introduce performance metrics in section \ref{metrics} and 

\subsection{Who decides the video streaming?}\label{designchoice}
For video streaming service decision making, there are three different models: \emph{In-network}, \emph{strictly end-to-end} and \emph{End-to-end with in-network knowledge}. 

\emph{In-network techniques} make decisions for users: it selects the video bit rate and schedule the download for users based on its knowledge of the network condition. However in-network approaches lack the insight of the video play progress, e.g., video buffer occupancy since it does not deal with any video decoding. Aside from technical reasons, here are several privacy/policy reasons for not doing this: most content providers are using encrypted http connections which ISPs cannot access; users may be concerned about their data budgets and thus not choose high bit rate; or content providers have different video play bit rate policies for different users based on their subscription contracts. 

\emph{End-to-end techniques} probe the network condition based on round trip time (RTT) and historical throughput, however existence of the proxy makes the RTT very inaccurate as it splits tcp connections. The dynamic nature of the wireless link makes historical data unable to capture the link behavior, e.g. the available bandwidth may plummet due to fading effects or handoff and recovers very soon after, current end-to-end approaches fail to react to those scenarios in most cases.

\emph{End-to-end with in-network knowledge} model addresses the above issues: instead of making the decision for the client; the network helps video streaming service make better decisions via offering some key performance metrics about the network condition, such as available throughput and handoff. 

Though an end-to-end with in-network knowledge approach has advantages over the other two, we still need to address the problem of how to expose the in-network knowledge in a least intrusive way in a scalable manner. 







\subsection{Architecture}\label{architecture}

We propose a two-tiered system for to implement OpenCell system. The two parts sit in RAN and EPC respectively. 

At the lower tier we have bandwidth estimator for each eNodeB. Estimating link channel quality and cell load is much more scalable if if we compute it at eNodeBs, since there are only hundreds of users at each cell, while aggregated number of users for a SGW can be tens of thousands. Making an estimation at second level means for each user the computational cycle is ~1 $ms$ if sitting at eNodeBs and ~10  $\mu s$ if sitting at Serving Gateway. Processing the raw information such as RSRQ from eNodeBs and extract it as estimated bandwidth also reduces the extra traffic generated for message passing. 

At the higher tier, the information inferred at eNodeBs are received at the proxy, and combined with handoff information, we make a final estimation of available bandwidth for each user and then expose this piece of information to application service providers by some means. The architecture is in figure \ref{cellular}.

\begin{figure}[t]\label{cellular}
\begin{minipage}[b]{\linewidth}
\centering
 \includegraphics[width=\linewidth]{cellular.pdf}
\end{minipage}
\caption{OpenCell Design}
\end{figure}

In terms of how to expose the API information, there are three options: encapsulation (i) at TCP/IP layer, (ii) at application layer; and (iii) using a distinct channel. Each approach has its pros and cons, for example TCP/IP layer does not require DPI but the fields used for encapsulation might be overwritten deep in the network from middleboxes. Using distinct channel does not suffer either problem but it requires application service providers' cooperation. We are still weighing between the options and leave this as a future problem. 



\end{comment}
