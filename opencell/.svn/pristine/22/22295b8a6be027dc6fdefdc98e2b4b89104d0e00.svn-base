
\section{Architecture} \label{sec:Architecture}
This section starts with the architecture of a scalable prediction system in
\autoref{subsec:prediction_system}, and then we discuss the feasibility and
advantages of inline method to expose APIs in \autoref{subsec:exposingAPI}.
\subsection{Scalable Prediction System} \label{subsec:prediction_system} We
propose a two-tiered system to implement an KPI computing system. We have a
proxy sitting at dataplane; and local and central bandwidth estimator at control
plane. The local bandwidth estimator communicates with eNodeBs and it takes
channel quality, number of active users, cell load and users' queue size etc.
information as inputs and compute the available bandwidth for each user. A local
bandwidth estimator is logically distributed in the RAN and thus can be easily
scale-out. Meanwhile the central bandwidth estimator sits in the core network
and it summarizes local BW estimation and MME Mobility information to compute
the final bandwidth prediction for a user. In most cases one local estimation is
enough, however in cases like handoff we need choose among several local
estimations. Central estimators can be
scale-out with MMEs. Our architecture is generic and able to integrate into both
3G and 4G networks. 

Once the computation work is finished, the central estimator sends the
information to the proxy. 
 
\begin{figure}[tb]\label{fig:Architecture}
 \includegraphics[width=\linewidth]{architecture2.pdf}
 \caption{Architecture for KPI Computing And Feedback}
\end{figure}


\subsection{KPI Exposure}\label{subsec:exposingAPI}
Current cellular networks already deploy proxies in the core network for
pacing purpose.\cite{UntoldMiddleBoxStory} It splits the TCP connection into two: server$\leftrightarrow
$proxy and proxy$\leftrightarrow $client. We can utilize the proxy for KPI
exposure. \emph{Sending to the server or the client?} We argue that exposing the
KPIs to the server causes less security concerns. It also reduces the traffic in
the core network as sending to the client requires central estimator to send
back to local ones again. However since we let the server decide and the server in practice
may send back to the client's application side. 

In terms of encoding the KPIs, there are several options: (i) in TCP; (ii) in
HTTP; and (iii) through a new connection. Inline methods have advantages over
new connection. First new connection method doubles the connections between the
server and the proxy. Second in practice CDNs are using public IPs, and the
video streaming and new exposure connection may be directed to different private servers in CDN
load balancer. Between inline methods TCP is more practical since many streaming
services are using secure HTTP which requires encrytion/decryption to modify the
header. Since most of the video traffic is from the server to the client, and
only some playback acknowledgement packets are sent from the client to the
server, extending the option fields in TCP from the proxy to the server only
adds moderate amount of overhead in TCP.\xin{Would any middleboxes on the
Internet (between the proxy and the server) modify/drop the TCP option fields?}

\xin{Can we say a bit more about API here? What do the APIs look like? Give an
example and show how it is encoded in TCP option field.}

