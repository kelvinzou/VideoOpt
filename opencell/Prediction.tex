\section{Measurement study}\label{sec:prediction}
In this section we conduct an extensive measurement study to show the predictability of a few key metrics that affects the available throughput. 

Proportional fair schedulers have been widely deployed in 3G and 4G networks to achieve high spectrum efficiency. It takes the channel conditions and the number of active users as inputs and schedules packets accordingly. In this section, we study how accurate prediction can give us for the two key inputs-channel condition and the number of active users. The information can be mapped to an available throughput, however we have not fully explored the underline relation between them. This approach is different from end-to-end monitoring approaches as it does not require constantly saturating the link to get the maximum bandwidth. 

The traces are collected for 5 minutes in Jun 2014 over several geolocations in the United States from one major 4G network carrier, it covers more than half million users and over 2000 eNodeBs. The traces have been anonymized before handing to us for privacy reasons. 

\begin{comment}
\subsection{Proportional Fair Scheduler}\label{subsec:ltenet}
3G ad 4G networks are using Orthogonal Frequency-Division Multiuser Access(OFDMA) scheme to achieve high spectrum efficiency. To achieve multiuser diversity, NodeBs and eNodeBs are running variations of proportional fair scheduling system. A basic \textit{proportional fair scheduler} works as the following: eNodeBs obtain the feedback from each user about their instantaneous channel quality conditions (CQ) in terms of encoding rate per resource block, and take the ratio between it and historical mean of CQ and pick the user with the maximum ratio. In a static model over a long term, each user will get 1/N share of resource blocks if N is the static number of users in the cell, a dynamic model also has a similar result\cite{PFINFOCOM}. The maximum bandwidth for each user in a cell is a function of: $T$-number of resource blocks in the cell, $N$-number of users in the cell, and $\mathbf{CQ}$-channel quality vector for all users; so maximum bandwidth vector for all users $\mathbf{BW} = f(T, N, \mathbf{CQ})$. We do not directly address $f(T, N, \mathbf{CQ})$ function in this paper as it is a vendor-specific PF-based scheduler. In the rest of the paper we assume a simple PF scheduler model, that is $\mathbf{BW} = f(T, N, \mathbf{CQ})=\frac{T}{N}*\mathbf{CQ}$. Among the three variables, $T$ is predetermined by the hardware, $N$ and $\mathbf{CQ}$ are the two factors we need to predict. 
\end{comment}

%\subsection{Bandwidth Estimation} \label{subsec:Prediction}


\subsection{Predictability}
There are many different metrics to compute the accuracy of a prediction, such as Mean Absolute Percentage Error (MAPE), Mean Square Percentage Error (MSE). In this paper we use MAPE since it can give us a good hint about how much off the prediction is from the true value for each step. In addition, we have the analysis of Cumulative Forecast Error (CFE), as it indicates how biased the prediction is over a long term. 

\begin{figure}[t]

\begin{minipage} {\linewidth}
\centering
 \includegraphics[width=\linewidth]{pictures/prediction.png}
\end{minipage}
\hspace{0.5cm}
\begin{minipage} {\linewidth}
\centering
 \includegraphics[width=\linewidth]{pictures/UE.png}
\end{minipage}

\caption{prediction for channel quality and active UE} \label{fig:prediction}
\end{figure}

\subsection{Channel Quality}\label{subsec:CQ}
One unique characteristic for cellular network is the high mobility and this causes the link quality to fluctuate to a certain extent.

\emph{RSRQ:} Reference Signal Received Quality, is the key metric for the LTE wireless channel. RSRQ senses the load from other users in the same cell and the neighboring cells, and is indexed in 0-34 integer numbers; a higher number indicates a better link quality. RSRQ values can be mapped to certain encoding rate.

We predict the future RSRQ using time series analysis, in particular we use ARIMA (Auto-Regressive Integrated Moving Average) model: the algorithm fits the best ARIMA with historical data, and it uses a sliding window as the training dataset. We set window size to 15. (We tried longer window but see no significant improvement over accuracy.) 

Through replaying 113 sample traces where the UEs are active for more than 100 seconds, we found that MAPE$<0.18$ for all the users, and the mean value is $0.064$. CFE values varies more across users with a maximum CFE=34.6, this is about three times of a unit value. In other words, for a 100 seconds prediction, prediction result may be 97\% accurate over long term. 

The above results tell us that a simple prediction model such as ARIMA can offer a fairly accurate prediction. 

\subsection{Cell Load}\label{subsec:NUser}
We measured the number of active users in each cell from the same trace as mentioned above. The trace is collected from UE's RSRQ reports to eNodeBs. We assume a user is active in a certain second if the user reports RSRQ in a one-second interval. 

We apply ARIMA model, and find in most cases random model fits the distribution the best. Different cells have different load, and the prediction works better in a heavily loaded cell. Since the inverse value of the active user number has strong correlation with available bandwidth for each user, we take the inverse value to compute MAPE and CFE. For heavily loaded cell ($>30$ UEs) we have MAPE$<0.1$ and CFE$<2$, medium loaded cell (5-30 UEs) MAPE$<0.5$ and CFE$<10$. This tells us we can achieve 90\% accuracy over long term. 



\begin{comment}

\section{Design} \label{sec:optimization}
In this section, we explain the reason to choose an \textbf{\emph{end-to-end decision making with in-network knowledge}} model in section \ref{designchoice}, we then explain the our architecture in section \ref{architecture}. 
%introduce performance metrics in section \ref{metrics} and 

\subsection{Who decides the video streaming?}\label{designchoice}
For video streaming service decision making, there are three different models: \emph{In-network}, \emph{strictly end-to-end} and \emph{End-to-end with in-network knowledge}. 

\emph{In-network techniques} make decisions for users: it selects the video bit rate and schedule the download for users based on its knowledge of the network condition. However in-network approaches lack the insight of the video play progress, e.g., video buffer occupancy since it does not deal with any video decoding. Aside from technical reasons, here are several privacy/policy reasons for not doing this: most content providers are using encrypted http connections which ISPs cannot access; users may be concerned about their data budgets and thus not choose high bit rate; or content providers have different video play bit rate policies for different users based on their subscription contracts. 

\emph{End-to-end techniques} probe the network condition based on round trip time (RTT) and historical throughput, however existence of the proxy makes the RTT very inaccurate as it splits tcp connections. The dynamic nature of the wireless link makes historical data unable to capture the link behavior, e.g. the available bandwidth may plummet due to fading effects or handoff and recovers very soon after, current end-to-end approaches fail to react to those scenarios in most cases.

\emph{End-to-end with in-network knowledge} model addresses the above issues: instead of making the decision for the client; the network helps video streaming service make better decisions via offering some key performance metrics about the network condition, such as available throughput and handoff. 

Though an end-to-end with in-network knowledge approach has advantages over the other two, we still need to address the problem of how to expose the in-network knowledge in a least intrusive way in a scalable manner. 







\subsection{Architecture}\label{architecture}

We propose a two-tiered system for to implement OpenCell system. The two parts sit in RAN and EPC respectively. 

At the lower tier we have bandwidth estimator for each eNodeB. Estimating link channel quality and cell load is much more scalable if if we compute it at eNodeBs, since there are only hundreds of users at each cell, while aggregated number of users for a SGW can be tens of thousands. Making an estimation at second level means for each user the computational cycle is ~1 $ms$ if sitting at eNodeBs and ~10  $\mu s$ if sitting at Serving Gateway. Processing the raw information such as RSRQ from eNodeBs and extract it as estimated bandwidth also reduces the extra traffic generated for message passing. 

At the higher tier, the information inferred at eNodeBs are received at the proxy, and combined with handoff information, we make a final estimation of available bandwidth for each user and then expose this piece of information to application service providers by some means. The architecture is in figure \ref{cellular}.

\begin{figure}[t]\label{cellular}
\begin{minipage}[b]{\linewidth}
\centering
 \includegraphics[width=\linewidth]{cellular.pdf}
\end{minipage}
\caption{OpenCell Design}
\end{figure}

In terms of how to expose the API information, there are three options: encapsulation (i) at TCP/IP layer, (ii) at application layer; and (iii) using a distinct channel. Each approach has its pros and cons, for example TCP/IP layer does not require DPI but the fields used for encapsulation might be overwritten deep in the network from middleboxes. Using distinct channel does not suffer either problem but it requires application service providers' cooperation. We are still weighing between the options and leave this as a future problem. 



\end{comment}
