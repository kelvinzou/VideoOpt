\newcommand{\rks}[1]{\textcolor{magenta}{#1}}
\section{Video Streaming optimization}\label{sec:optimization}

We design a video rate selection algorithm to exploit reliable
prediction of available future bandwidth.

% The impact of reliable prediction of available bandwidth , how this
% can be reflected in the improvement of video streaming service has not
% been explored. In this section we show that the algorithm can use the
% available bandwidth as a key information and make a smart decision.  

We start by defining performance metrics for video streaming service in
\autoref{subsec:metrics}. The goal of the video rate selection is to 
optimize these metrics.
% takes the metrics into consideration during video quality selection. 
In \autoref{subsec:offline}, we design an offline algorithm, OPT, that
takes, as input, available bandwidth during the entire session and
selects video quality for each chunk duration. For a certain video play bit rate, We assume the encoding rate is
constant.

\rks{Should we state upfront that we are assuming video is coded in CBR?
  Otherwise, the offline algorithm will have to know all
  available bandwidth and all possible chunk sizes.}
  \kelvin{yes, i will do that, how's the last sentence in the last paragraph}
  
The performance of this algorithm forms an upper bound on possible
gains from knowledge of future bandwidth.
In \autoref{subsec:online}, we present our final algorithm that, for
each chunk, selects a video rate  based on prediction of 
available bandwidth in the \emph{near} future.

\rks{It is not very clear if we are (a) designing a video rate
  selection algorithm that is simply better than BBA, FESTIVE,
  etc. while using the similar information as those guys,
  or (b) custom designing an algorithm to exploit knowledge of future
  bandwidth? If it is the latter, it needs to be pointed in the
  text. E.g., we can afford to be more aggressive because we have
  higher confidence in our bw estimate. If it is the former, it is a
  very strong claim that needs more validation.}

\kelvin{To answer your question, I think this might be  both, FESTIVE also uses estimated bandwidth in a conservative manner, so their stability adjustment is simpler. I tried to use
FESTIVE with prediction, but it cannot just fit in seamlessly}

\subsection{Performance Metrics}\label{subsec:metrics}

\rks{We seem to use capacity and bw synonymously; Better to pick one
  and use it consistently. Same with chunk/segment}
  \kelvin{I will try to keep them consistent}

We quantify the performance of our algorithm with the following three
metrics, which have been extensively used in prior research work in video
streaming 
\cite{Qava, Avis,VideoMeasurement, Festive}. 

% To help us understand what extra benefit we can achieve from new
% information, we define \emph{three} performance metrics for video
% streaming. These metrics have been extensively studies in various
% video streaming algorithms and we use the metrics in both design and
% evaluation\cite{Qava, Avis,VideoMeasurement, Festive}. 

\begin{enumerate}
\item\textit{Quality}: as the video download is chunk-based, a video
  session can consist of chunks with different qualities (bit
  rates). The video player should download the chunk with the highest
  possible quality based on available bandwidth at each download point
  to give user better quality experience. We define quality as the
  ratio of 'total size of downloaded and played video' and 'sum of bandwidth.'

\item\textit{Stability}: From viewer's perspective, frequent rate
  switches are distracting and undesirable. Our goal is to minimize 
  % To assess the stability of video streaming, we  define
  \emph{fluctuation cost}, defined as the number of rate switches, $\phi= \sum\limits_t
  \mathbf{1}(R^t!=R^{t-1})$, where $\mathbf{1}$ is an indicator
  function. 

  \rks{"fluctuation cost" or "instability?"}

  \kelvin{We dont use it as cost any more, but do put it in performance measurement.}
  
\item\textit{Interruption and rebuffering}: Video play should not be
  halted for rebuffering video chunks, otherwise user experience will
  be severely degraded. Video play interruptions affect the user
  engagement and results in early abandonment of the video play
  \citation{Vyas QoE paper}. We minimize the 
  number of interruptions over the entire session. % whole play time. 
\end{enumerate}

\begin{table} [bt]
\small
\begin{tabular} {|c |l |}
\hline
\textbf{Symbol}&\multicolumn{1}{c|}{\textbf{Meaning} }\\ \hline
$T$ &number of time segments\\ \hline
$M$ &number of video quality levels (encoding bit rates)\\ \hline
$R_i$& rate for the video with $i^{th}$ highest encoding bit rate \\ \hline
$x_i^t$& binary variable indicating whether $R_i$ is the video \\
& play rate at time $t$ \\ \hline
% indicator of encoding of $R_i$ video play rate at time t
$E$& utilization of video download over available bandwidth \\ \hline
$\phi$ &number of video rate switches \\ \hline
% for a video play
$C $ & estimated capacity for the next chunk\\ \hline
$B $ & buffer occupancy (seconds of video) \\ \hline
$z $ &maximum buffer size (seconds of video) \\ \hline
$B_{risk} $ & threshold for buffer occupancy. Below this threshold is\\
& 
risky phase; above this threshold is safe zone \\ \hline
\end{tabular}
\centering
\caption{Variables and parameters for optimization}
\label{tab:notation}
\end{table}
\subsection{Video Quality Upper Bound}\label{subsec:offline}
\rks{is $R_i$ rate (Mbps) or chunk size (MB) at that quality? In your formulas, you seem to be using as chunk size.} 

Given the available bandwidth for the entire video play
session, we want to know the optimal video rates for each chunk. This
is an idealization of our real problem, where we only know (with high
confidence) available bandwidth for a few chunks.
We formulate a Mixed Integer Linear Program (MILP) with the goal of
maximizing quality without causing any interruptions.

\rks{Why are we ignoring stability?} 

% quantify video quality (play efficiency)
% upper bound, e.g., 
% and play to best
% utilize the available bandwidth. We prioritize interruption-free and
% allow prefetching unlimited video chunks.  

Table~\ref{tab:notation} lists the variables and parameters.
In reality, we need chunks ahead of their actual playing
time. E.g., we need one chunk before we can start the video. To keep
this formulation simple, we ignore this restriction here.

To ensure  no interruptions, at each time segment, the total download
should not exceed the sum of capacities till that segment.
% always be at least be equal to video played 

% For simplicity, we assume that at the initial
% state,  
% the client video buffer contains one chunk ahead of playing.
% ), i.e.,

\rks{In the definition of $E$, it appears that you are using $D^t$ to
  denote download rate at time   $t$ so I defined it here?}

The download at time $t$ is given by 
$D_t = \sum \limits_{i=1}^M R_i *  x_i^t$. 
The zero-interruptions constraint is 
$\sum \limits_{t=1}^\tau D^t\leq\sum\limits_{t=1}^\tau C^t$
for $\forall \tau \in \{1, \dots, T\}$.
As stated earlier, 
quality (play efficiency) 
%at the end of a video session, the play efficiency 
is the overall utilization of the available bandwidth
over time period $[1:T]$, defined as
% , we use ratio of the throughput used for
%video downloading and playing over the available bandwidth:
$\bar{E}=(\sum\limits_{t=1}^T D^t)/(\sum\limits_{t=1}^T C^t)$. 
\rks{In the table, we have $E$. Here we have $\bar{E}$. Are they the
  same?}
The MILP for maximizing quality without causing interruptions is
\begin{subequations}
\begin{align*}
&\textsc{maximize }&\bar{E}\\ 
&\textsc{Subject to}\\
%&\sum \limits_{t=1}^\tau  \sum \limits_{i=1}^M R_i \cdot
%x_i^t\leq\sum\limits_{t=1}^\tau C^t& \forall \tau \in \{1, \dots,
%T\}\\
&\forall \tau \in \{1, \dots, T\}, \sum \limits_{t=1}^\tau  D^t
\leq\sum\limits_{t=1}^\tau C^t \\
& \forall t, \sum \limits_{i=1}^M x_i^t =1\ \\
& \forall t, i, x_i^t = \{0,1\}
\end{align*}
\end{subequations}

\subsection{Video Streaming Algorithm} \label{subsec:online}

In the algorithm, we assume that the available bandwidth forecast for
a small time interval is known.
(In the evaluations, we are assuming that we know the bandwidth for
the next chunk.)
% in this paper we assume bandwidth estimation for one video chunk. 
The algorithm is a joint optimization
solution based on both the video buffer occupancy and the estimated
\rks{predicted?} bandwidth. 
\rks{How exactly are we taking advantage of the prediction?}

We motivate our algorithm with a naive solution: pick the maximum
 play bit rate that can be supported by the known future bandwidth. 
There are several shortcomings: (i) the stability may be heavily
impacted due to highly variable bandwidth values, and (ii)
%interruptions may occur 
because we are using all of the bandwidth for maximizing quality of
the video, there is a good chance that our playout buffer will not
have many chunks. 
Connection loss (zero or near zero bandwidth) of several seconds is
not uncommon in  cellular networks but these may drain out the buffer
and result in video interruption and rebuffering.
% It is not uncommon in cellular networks to 
%  and video will have interruptions if we face
% a few or even tens of seconds

% network. 
To avoid this, we divide the
buffer into two zones -- risky and safe -- based on buffer occupancy
threshold $B_{risk} $. In risky zone, we have low buffer occupancy and
a high chance of buffer over-drain. So we try to build the buffer by
picking one rate lower than what the available capacity can support.
%  we decide to step down our quality by one, 
E.g., if the bandwidth is $0.58$Mbps and two closest video
bit rates are $0.56$ and $0.375$, we choose $ 0.375$ as an
ideal bit rate for the bandwidth in the risky zone. 
 therefore we can
fill in the client buffer to safe phase faster. 
\rks {So we request one chunk at $0.375$ and then do we request
  another chunk right away to build the buffer?}
In the safe phase
\rks{I prefer "zone'' over "phase" but I will leave as it is until we talk.} we
pick the highest available bit rate which is $0.56$Mbps in our
example. We call this computed bit rate referred bit rate, $R_{ref}$.
%  Choosing referred bandwidth would give us high play efficiency.  

\begin{algorithm} [t]
\SetAlgoLined
 \KwData{ $C$: Predicted available bandwidth \newline$\mathbf{B}$:
   Buffer occupancy vector for last $t$ chunks\newline$R_{cur}$: Current video bit rate}
 \KwResult{$Rate$: Rate for next chunk. \newline\rks{Should we use
     input/output instead of data/result?} }
pick MAX($R_{ref}$) where $R_{ref}<C$\;
\rks{ Did you mean pick $R_{ref} = MAX{R_i \le C}?$,\;}
 \uIf{$B'\leq B_{risk} $}{
\rks{ Is $B'$ same as $B_t$?}
 pick MAX($R_{ref-1}, R_{min}$)\;
\rks{Don't understand the previous stmt! Do we exit or can we still go
  to the next if block?}
 }
 \uIf{$R_{ref}<R_{cur}$ and $B'<B_{risk}$ }
 {
\rks{May be good idea to put comments. E.g. pick the highest rate
  where the resulting loss is less than increase in buffer occupancy
  during last $k$ chunks.}
 \For{ $R\in [R_{ref}, R_{cur}]$}
 {
 $BLoss=ChunkSize*\frac{R-C}{C}$\;
 $\Delta B = B_{t} -B_{t-k} $\;
 \uIf{$\Delta B>BLoss$}
 {Rate=$R$}
 }
 }
 \Else{
 \uIf{$R_{ref}>R_{cur}$} {
 \For{$R\in [R_{cur}, R_{ref}]$}{
 $BLoss=\alpha * (B-z) *\frac{R-R_{cur}}{R_{cur}}$\;
  $\Delta B = B_{t} -B_{t-k} $\;
 \uIf{$\Delta B>BLoss$}
 {Rate=$R$}
 }
 }
 }
\caption{Rate Selection} \label{cap:algorithm}
\end{algorithm} 

The algorithm considers the stability in the following manner: it
compares the referred play bit rate and current play bit rate, and
chooses the referred or current bandwidth or other play bit rates
between them based on a certain criteria. It uses delayed updates
based on the buffer occupancy status and uses ideas similar to what
was proposed in BBA \cite{BBA} and FESTIVE \cite{Festive} algorithms.

If $R_{ref} < R_{cur}$, since the current play bit rate is higher, the
algorithm may choose current play bit rate at the cost of draining
client video buffer. If the buffer size is in safe phase, the
algorithm takes the risk and adheres to current play bit rate. If the
buffer is in risky phase, it computes the possible buffer drain if
choosing the current play bit rate $BLoss
=ChunkSize*\frac{R_{cur}-BW}{BW}$ 
\rks{please explain this formula. Is BW same as C?}
, and compare the buffer change in
the last $k$ chunks 
\rks{$k$ another parameter? Should we include in the table?}
$\Delta B = B_{t} -B_{t-k}$, where $B_{t}$
represents the buffer occupancy at the end of $t^{th}$ chunk
download. If the buffer change in the last $k$ chunks is positive and
sufficient to compensate the buffer drain for next video chunk, the
algorithm chooses the current play bit rate, otherwise it chooses the
highest bit rate which can suffice this criterion. This step
essentially avoids interruption while ensuring stability. 
\rks{The overall effect is a positive buffer gain in the last $k+1$
  steps.}


If $R_{ref} >R_{cur} $, though the referred play bit rate is higher,
the high available bandwidth may be for short period of time and the
algorithm needs to check buffer gain in the last few chunks against
potential buffer loss. In addition to that, if the buffer occupancy is
high, the algorithm should be more aggressive and jump up faster and
vise versa. To add this factor, we compute potential buffer loss for
$k'$ chunks where $k'$ is in linear relation to unfilled buffer
$B'=z-B$, $k'=\alpha * B'/ChunkSize$ 
\rks{$\alpha$ another parameter? Should we include in the table?}
where $\alpha$ is a tunable knob. We assume a conservative case in the
future where the network has enough capacity to stream at current bit
rate with no client buffer loss or gain, so potential $BLoss=\alpha *
B' *\frac{R-R_{cur}}{R_{cur}} $. If the value is less than buffer
gain, we decide to overdrain buffer with the new play bit rate. This
step boosts stability \rks{how? Why does this result in fewer switches?}.

The online algorithm continuously estimates the bandwidth for the next
time segment and selects the bit rate and download unless the client
buffer is totally full at size z, as shown in
\autoref{cap:algorithm}. 
\rks{Should the algorithm contain a condition for when buffer is full
  $= z$?}
\rks{I am not sure when we download a chunk. As soon as the previous
  one finishes downloading?}


%State-of-the-art video streaming algorithms \cite{BBA, Festive} share great similarities in a few aspects: (i) deferred updates of video bit rate over link condition, (ii) periodic download if video buffer is full. Our design also applies the same concepts.

% \textbf{We also show that by integrating our KPIs existing algorithm can also improve its video streaming performance, but the improvement is limited by its mismatched design where KPIs were not considered. NOT DONE YET} 

%For interruption, unlike quality and stability which can be easily
%quantized in the algorithm, we need take an alternative view via
%looking at the video buffer occupancy, in particular we should avoid
%the video buffer empty. There is a tradeoff between prefetching,
%quality and interruption. Prefetching many video chunks is (i) not
%efficient, as it conservatively downloads more video chunks and play
%at lower quality; and (ii) wasteful if the viewer abandons the video
%session. We factor in the video buffer occupancy to adjust requested
%download bit rate. If the buffer occupancy is high we can take a risk
%to download at higher rate beyond the estimated bandwidth and if the
%buffer occupancy is low we may conservatively download at lower rate
%than estimation. The video buffer occupancy can be used as a
%discount/inflation factor for the estimated bandwidth: when the
%buffer occupancy is low, we use the discounted bandwidth estimation
%and download more chunks with lower rates to fill the buffer, when
%the buffer occupancy is high we use the inflated bandwidth to drain
%the buffer a little faster. We define inflation as a concave
%function: $f(B)= \log(1+\frac{B}{B_{rec}})$, where $B_{rec}$ is the
%recommended equilibrium buffer size.   

%For stability, we use exponential penalty for play bit rate jump and
%define the fluctuation $COST = 2^{\phi} *e^{-\alpha *\Delta t}$. The
%reason is to discourage but not to disallow a jump of more than one
%level. We also add an exponential time decaying where $\Delta t$
%represents the time interval since last bit rate changes and $\alpha$
%is a tunable parameter to reflect the time significance. For
%efficiency, we take the inverse of link utilization over inflated
%bandwidth to penalize the under-utilized bandwidth: $\frac{1}{E} =
%\frac{C}{BitRate}*\log(1+\frac{B}{B_{rec}}) $. Combine this and the
%fluctuation cost with a tunable knot, we have a score function
%$Score= \frac{1}{E} + \beta*COST$. In practice we set $\alpha=0.01$
%and $\beta=1.2$ have the best performance. 


%We use the bit rate= $\argmin{(Score)}$ as the recommended video bit
%rate. We further delay the video bit rate step up or step down based
%on $B$ buffer occupancy and $\Delta B$ buffer change from last chunk
%download via the following mechanism to absorb the high link
%fluctuation, while $Score$ function absorbs low and median bandwidth
%fluctuation. We divide the buffer occupancy into two zones: risky
%$[0,B_{rec}]$ and safe $[B_{rec},z]$. In risky zone, if the client
%video buffer is depleting, if $\Delta B>0$ we defer the video bit
%rate stepping down, as it may just be a short period of low
%throughput. When $B$ is in safe zone we take more risk and step down
%if $\Delta B < -\frac{B_{rec}}{2}$ which means if the buffer is
%depleting substantially and a preemptive action is needed before
%stepping into risk zone. Stepping up is allowed since in risky phase
%the bandwidth is already a discounted bandwidth, and in safe phase we
%have sufficient buffer.  
  
